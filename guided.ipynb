{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle swarm optimization (PSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from paper import PSO, Mode\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Papers\n",
    "\n",
    "[Particle Swarm Optimization](https://www.cs.tufts.edu/comp/150GA/homeworks/hw3/_reading6%201995%20particle%20swarming.pdf) - Kennedy and Eberhart 1995\n",
    "\n",
    "[A Modified Particle Swarm Optimizer](https://www.researchgate.net/profile/Yuhui-Shi/publication/3755900_A_Modified_Particle_Swarm_Optimizer/links/54d9a9700cf24647581f009e/A-Modified-Particle-Swarm-Optimizer.pdf?origin=publication_detail) - Shi and Eberhart 1998\n",
    "\n",
    "#### Motivation\n",
    "* Method was discovered through the **simulation of a social behavior model**\n",
    "    \n",
    "    > <br /> “In theory at least, individual members of the school can **profit** from the discoveries and previous experience of **all other members** of the school during the search for food. This advantage can become decisive, **outweighing the disadvantages** of competition for food items, whenever the resource is unpedictably distributed in patches\"\n",
    "    >\n",
    "    > \\- sociobiologist E. O. Wilson in reference to fish schooling<br />&nbsp;\n",
    "        \n",
    "* Allows optimization of **continuous nonlinear functions** without the need for them to be **convex or differentiable**\n",
    "\n",
    "* Proved to be effective **training neural network weights** as well as optimizing **genetic algorithm test functions** such as Schaffer's f6 \n",
    "\n",
    "##### Basic idea\n",
    "\n",
    "> <br /> The algorithm works by having a **population** (aka swarm) of **candidate solutions** (aka particles). \n",
    ">\n",
    "> These particles are moved around in the search-space based on their **own best-known position** as well as the **entire swarm's best known position**. \n",
    "> \n",
    "> By repeating these movements it is hoped, but **not guaranteed**, that a satisfactory solution will eventually be discovered. [ref](https://en.wikipedia.org/wiki/Particle_swarm_optimization#Algorithm)<br />&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development of algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Nearest Neighbor Velocity Matching and Craziness\n",
    "\n",
    "Population randomly initialized on a torus pixel grid with both x and y velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Nearest Neighbor Velocity Matching\n",
    "\n",
    "* at each iteration → each agent is assigned the velocity of its nearest neighbor\n",
    "        \n",
    "* cons → quickly settled on a unanimous, unchanging direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Mode.NNVM, particles=2)\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Craziness\n",
    "\n",
    "* at each iteration → some change was added to random chosen X and Y velocities\n",
    "<br/><br/>&nbsp;&nbsp;&nbsp;&nbsp;- doubt → `fixed` change to `some` velocities or `random` change to `all` velocities?\n",
    "\n",
    "* gave the simulation a \"lifelike\" appearance though the variation was wholly artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Mode.NNVM_CRAZINESS, particles=16, duration=1000)\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cornfield vector\n",
    "    \n",
    "* Heppner's bird simulations had a dynamic force\n",
    "    \n",
    "    * birds flocked around a \"roost\" → position on the pixel screen that attracted them until they landed there\n",
    "    \n",
    "    * removes the need for `craziness`\n",
    "* A two-dimensional vector of XY coordinates on the pixel plane was introduced → i.e function to be optimized\n",
    "\n",
    "    $$Eval = \\sqrt{(presentx-100)^2}+\\sqrt{(presenty-100)^2}$$\n",
    "\n",
    "    * Rule to change velocity\n",
    "        \n",
    "        * Each agent \"remembers\" best value and the (x,y) that produces it\n",
    "        \n",
    "            $$v_x[\\space] = \\begin{cases}\n",
    "                v_x[\\space] - rand()*p_{inc} &\\text{if } current_x[\\space] > pbestx[\\space]  \\\\\n",
    "                v_x[\\space] + rand()*p_{inc} &\\text{if } current_x[\\space] < pbestx[\\space]\n",
    "            \\end{cases} $$\n",
    "\n",
    "        * Each agent “knows” the global best position and its value\n",
    "        \n",
    "            $$v_x[\\space] = \\begin{cases}\n",
    "                v_x[\\space] - rand()*g_{inc} &\\text{if } current_x[\\space] > pbestx[gbest]  \\\\\n",
    "                v_x[\\space] + rand()*g_{inc} &\\text{if } current_x[\\space] < pbestx[gbest]\n",
    "            \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Mode.CORNFIELD_VECTOR, particles=16, p_inc=1, g_inc=1, duration=1500)\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminating ancillary variables\n",
    "\n",
    "* `craziness` was removed → algorithm looks just as realistic without it\n",
    "\n",
    "* `nnvm` was removed → optimization occured slightly faster\n",
    "\n",
    "* variables $pbest$ and $gbest$ and their increments are both necessary\n",
    "\n",
    "* equal values of $p_{inc}$ and $g_{inc}$ seem to result in most effective search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Mode.ONLY_CORNFIELD, particles=16, p_inc=0.1, g_inc=0.1)\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multidimensional search\n",
    "\n",
    "* changed from one dimensional arrays to $DxN$ matrices\n",
    "\n",
    "##### Experiments\n",
    "\n",
    "* `3-layer NN` (2-3-1) solving the exclusive-or (XOR) problem\n",
    "    \n",
    "    * particles flying 13-dimensional space until an **average sum-squared error per PE** criterion was met\n",
    "        \n",
    "        \\- doubt → calculated sum-squared error for each node and then the average had to meet certain criterion? why not just the last node?             \n",
    "\n",
    "    * trained to an $e$ < 0.05 criterion, in an average of **30.7 iterations** with **20 agents**\n",
    "\n",
    "* neural network to `classify` the Fisher Iris dataset\n",
    "\n",
    "    * over 10 training sessions → average of 284 epochs was required\n",
    "<br/><br/>\n",
    "\n",
    "* weights found by particle swarms sometimes `generalize better` than solutions found by gradient descent\n",
    "\n",
    "    * example dataset of electroencephalograms → 89% correct GD vs 92% correct PS\n",
    "    \n",
    "        \\- doubt → correct based on what metric?\n",
    "\n",
    "* benchmark with genetic algorithms found in Davis → the extremely nonlinear Schaffer f6 function\n",
    "    \n",
    "    * couldn't find the Davis and Schaffer f6 reference but the function somehow appeared in some websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceleration by distance\n",
    "\n",
    "- velocity adjustments were based on a crude inequality test\n",
    "- velocities are not adjusted according to their difference per dimension from best locations\n",
    "    \n",
    "    $$\n",
    "    v_x[\\space][\\space] = v_x[\\space][\\space] + rand()*p_{inc}*(pbest_x[\\space][\\space]- current_x[\\space][\\space])\n",
    "    $$\n",
    "\n",
    "#### Current simplified version\n",
    "- no good way to guess if $p_{inc}$ or $g_{inc}$ should be larger → removed from algorithm\n",
    "\n",
    "- stochastic factor multiplied by 2 to give a mean of 1\n",
    "\n",
    "$$\n",
    "v_x[\\space][\\space] = v_x[\\space][\\space] + 2 * rand() * (pbest_x[\\space][\\space] - current_x[\\space][\\space]) + 2 * rand() * (pbest_x[\\space][gbest] - current_x[\\space][\\space])\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Mode.CURRENT, particles=16)\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❌ reduce $pbest$ and $gbest$ terms into one\n",
    "- agent is propelled toward a weighted average of the two “best” points\n",
    "\n",
    "- converges to that point whether optimum or not\n",
    "\n",
    "- two stochastic “kicks” are needed\n",
    "\n",
    "#### ❌ two types of agents → explorers and settlers\n",
    "- explorers used the inequality test while settlers used the difference term\n",
    "\n",
    "- hypothesis was that explorers would extrapolate outside the “known” region and settlers would micro-explore regions that had found to be good\n",
    "\n",
    "#### ❌ remove momentum of $v_x[\\space][\\space]$\n",
    "- ineffective at finding global optima\n",
    "#### ✅ inertia weight $w$ is added to balance global and local search (from extra paper)\n",
    "$$\n",
    "v_x[\\space][\\space] = w * v_x[\\space][\\space] + 2 * rand() * (pbest_x[\\space][\\space] - current_x[\\space][\\space]) + 2 * rand() * (pbest_x[\\space][gbest] - current_x[\\space][\\space])\n",
    "$$\n",
    "* small $w$ → PSO behaves more like a **local** search algorithm\n",
    "* big $w$ → PSO behaves more like a **global** search algorithm\n",
    "\n",
    "* motivation\n",
    "    * PSO without $v_x[\\space][\\space]$ → search space shrinks through generations → resembles local search\n",
    "    * By adding $v_x[\\space][\\space]$ → particles tend to expand the search space → more like global search\n",
    "    * as usual there is a tradeoff between global and local search\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Mode.EXTRA, particles=16, p_inc=0.1, g_inc=0.1, w=0.9)\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm as is, is `limited` to problems without restrictions.\n",
    "\n",
    "A simple `workaround` could be to add the restrictions through the use of `Lagrange multipliers`, i.e multiplied by a constant in the objective.\n",
    "\n",
    "However, since these papers were written there's probably lots of literature on how to tackle the problem effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swarm theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five basic principles of swarm intelligence\n",
    "|  | Name | Description |\n",
    "| --- | --- | --- |\n",
    "| 1. | Proximity principle | the population should be able to carry out **simple space and time computations** |\n",
    "| 2. | Quality principle | the population should be able to **respond to quality factors** in the environment |\n",
    "| 3. | Principle of diverse response | the population should not commit its activities along excessively narrow channels |\n",
    "| 4. | Principle of stability | the population **should not change** its mode of behavior **every time** the environment changes |\n",
    "| 5. | Principle of adaptability | the population **must be able to change** behavior mode when it's **worth the computational price** |\n",
    "\n",
    "How particle swarm applies to them\n",
    "\n",
    "|  | Name | Description |\n",
    "| --- | --- | --- |\n",
    "| 1. | Proximity principle | n-dimensional space calculations carried out over a series of time steps |\n",
    "| 2. | Quality principle | the population is responding to quality factors $pbest$ and $gbest$ |\n",
    "| 3. | Principle of diverse response | the allocation of responses between $pbest$ and $gbest$ ensures a diversity of response. |\n",
    "| 4. | Principle of stability | the population changes its state **only** when $gbest$ changes |\n",
    "| 5. | Principle of adaptability | the population **does** change when $gbest$ changes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <br/>The term particle was selected as a **compromise**. While it could be argued that the population members are **mass-less** and **volume-less**, and thus could be called “points”, it is felt that velocities and accelerations are more appropriately applied to particles, even if each is defined to have arbitrarily **small mass and volume**.<br/>&nbsp;\n",
    "\n",
    "> <br />The authors of this paper are a **social psychologist** and an **electrical engineer**. The particle swarm optimizer serves both of these fields equally well.\n",
    ">\n",
    "> Why is **social behavior** so ubiquitous in the animal kingdom? Because it **optimizes**. \n",
    ">\n",
    "> What is a good way to solve engineering **optimization** problems? Modeling **social behavior**.<br/>&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import ackley\n",
    "\n",
    "pso = PSO(\n",
    "    Mode.EXTRA,\n",
    "    particles=16,\n",
    "    grid_length=10,\n",
    "    p_inc=0.1,\n",
    "    g_inc=0.1,\n",
    "    w=0.9,\n",
    "    fitness_func=ackley,\n",
    "    grid_center=np.array([0, 0]),\n",
    ")\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import schaffer_f6\n",
    "\n",
    "pso = PSO(\n",
    "    Mode.EXTRA,\n",
    "    particles=16,\n",
    "    grid_length=200,\n",
    "    p_inc=1,\n",
    "    g_inc=1,\n",
    "    w=0.9,\n",
    "    fitness_func=schaffer_f6,\n",
    "    grid_center=np.array([0, 0]),\n",
    ")\n",
    "pso.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import himmelblau\n",
    "\n",
    "pso = PSO(\n",
    "    Mode.EXTRA,\n",
    "    particles=16,\n",
    "    grid_length=10,\n",
    "    p_inc=1,\n",
    "    g_inc=1,\n",
    "    w=0.9,\n",
    "    fitness_func=himmelblau,\n",
    "    grid_center=np.array([0, 0]),\n",
    ")\n",
    "pso.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7cf9db6b897a9ca3194603bdc6894357959488e6c4af78cf7ce2ad534944f815"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
